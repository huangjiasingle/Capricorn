# 疑难解答

### 基础知识

#### 1. TCP/UDP

![ebe986144d121cb24ca13b7f078edbfd](images/ebe986144d121cb24ca13b7f078edbfd.png)

运输层：提供的是进程间的通用数据传输服务。由于应用层协议很多，定义通用的运输层协议就可以支持不断增多的应用层协议。运输层包括两种协议：传输控制协议 TCP，提供面向连接、可靠的数据传输服务，数据单位为报文段；用户数据报协议 UDP，提供无连接、尽最大努力的数据传输服务，数据单位为用户数据报。TCP 主要提供完整性服务，UDP 主要提供及时性服务。

### tcp/udp 特点

用户数据报协议 UDP（User Datagram Protocol）是无连接的，尽最大可能交付，没有拥塞控制，面向报文（对于应用程序传下来的报文不合并也不拆分，只是添加 UDP 首部）

传输控制协议 TCP（Transmission Control Protocol）是面向连接的，提供可靠交付，有流量控制，拥塞控制，提供全双工通信，面向字节流（把应用层传下来的报文看成字节流，把字节流组织成大小不等的数据块）。

### tcp三次握手

![0bf911ba9e9329250073782105ac085b](images/0bf911ba9e9329250073782105ac085b.png)

假设 A 为客户端，B 为服务器端。

1. 首先 B 处于 LISTEN（监听）状态，等待客户的连接请求。
2. A 向 B 发送连接请求报文段，SYN=1，ACK=0，选择一个初始的序号 x。
3. B 收到连接请求报文段，如果同意建立连接，则向 A 发送连接确认报文段，SYN=1，ACK=1，确认号为 x+1，同时也选择一个初始的序号 y。
4. A 收到 B 的连接确认报文段后，还要向 B 发出确认，确认号为 y+1，序号为 x+1。
5. B 收到 A 的确认后，连接建立。

三次握手的原因

为了防止失效的连接请求到达服务器，让服务器错误打开连接。

![5752d0b36194270142504b34238cc5bf](images/5752d0b36194270142504b34238cc5bf.jpg)

1. A 发送连接释放报文段，FIN=1；
2. B 收到之后发出确认，此时 TCP 属于半关闭状态，B 能向 A 发送数据但是 A 不能向 B 发送数据；
3. 当 B 要不再需要连接时，发送连接释放请求报文段，FIN=1
4. A 收到后发出确认，进入 TIME-WAIT 状态，等待 2MSL 时间后释放连接。
5. B 收到 A 的确认后释放连接

四次挥手的原因

客户端发送了 FIN 连接释放报文之后，服务器收到了这个报文，就进入了 CLOSE-WAIT 状态。这个状态是为了让服务器端发送还未传送完毕的数据，传送完毕之后，服务器会发送 FIN 连接释放报文。

#### 2. 高并发/高性能 （进程/线程/协程）

[进程线程协程之间的区别和联系](https://github.com/xiezg247/Capricorn/blob/master/docs/笔记/知识体系/操作系统/进程线程协程之间的区别和联系.md)

**先来看一个例子：**

一个蓄水池，是1m*1m*1m=1立方米大小，有一个出水口，出水口每秒钟流出0.1立方米，那么这个蓄水池的并发量是1立方米，出水速度是0.1立方米/秒。

如果增加一个出水口，都是每秒钟流出0.1立方米，那么这个蓄水池的并发量没变，但是出水速度变成了0.2立方米/秒。

同理，增大了出水口，蓄水池的出水速度也变快了。

**上面我们很容易知道，并发量是一个容量的概念，性能就是出水速度，而且有下面这些结果。**

1 增大蓄水池的长宽高，可以增加并发能力。

2 出水口如果扩大了出口大小，则可以提高出水的速度，也就是性能提高了。

3 增加出水口的数量，则是增加了并行处理的能力，同样可以提高性能。

**那么对照我们计算机中，我们的系统中，是怎么样的结果呢？**

1 增加服务器的内存大小，可以增加并发量。因为内存增加了，就可以开更多的进程，更多的线程，也可以扩大任务队列的大小。

2 提高cpu的主频速度，优化程序，可以提高性能。cpu更快了，程序优化的更好了，处理单个任务的时间也就更短了。

3 增加多核甚至分布式服务器数量，也可以提高性能，同时提高并发量。

**看以下并发模型**

process : thread : task

    - 1:1:1 -> 单进程，单线程，单任务。例如阻塞型echo server
    - N:1:N -> 多进程，单线程，多任务。进程池
    - 1:N:N -> 单进程，多线程，多任务。线程池
    - 1:1:N -> 单进程，单线程，多任务。Python中的协程实现
    - 1:M:N -> 单进程，多线程，多任务。Golang的GMP模型
    - M:N:Z -> 多进程，多线程，多任务。Nginx的多worker，每个worker多线程，每个线程+epoll处理多请求
    - ...

多进程和多线程的模式，不仅是内存开销巨大，而且在数量不断增加的情况下，对CPU的压力也是非常巨大，这也是为什么这类系统在并发量大的情况下会很不稳定，甚至宕机。

上面假设中计算出来的数据，都是静态的容量，如果所有任务都不处理，那么肯定都是会很快就被撑爆。

所以要达到更高的并发量，就需要有更快的处理速度，即做好性能优化。

下面，再来做一个假设。

我们现在有一台服务器，配置是8核16G内存。

如果我们的应用是计算密集型，纯运算的系统，如：数据索引查询、排序等操作。

而且还要假设，这个应用在多核并行运算时不存在锁竞争的情况（只读）。

**qps=1000ms/单个请求耗时\*8**

如果单个请求（任务）耗时100ms，那么我们可以计算出来

qps=1000ms/100ms*8=**80个/秒**

如果我们优化处理的算法，单个请求耗时降低到10ms，那么

qps=1000ms/10ms*8=**800个/秒**

如果可以继续优化，将单个请求耗时降低到1ms，那么

qps就可以达到更高的**8k**。

上面的情况和优化的效果理解起来应该很容易，因为对服务器资源的依赖更多是CPU的运算能力和数量。

在实际的互联网应用中，系统更多是依赖mysql，redis，rest api或者微服务，属于IO密集型。

按照上面的计算方式，可能就不太准确了，因为cpu是有富余的。

**在IO阻塞的时候，开启更多任务的方式当然有上面多进程、多线程、多协程和队列的方式来实现。**

而且也是有效的更好的利用服务器资源的方法，可以达到更高的并发量，毕竟我们把大部分的运算放到了应用外部的mysql，redis，rest api等服务。

到此为止，我们已经知道并发量、性能优化跟服务器资源（服务器数量，cpu，内存）的关系，也知道性能优化对并发量的影响。

免创建、销毁、维护太多进程、线程，导致操作系统浪费资源在调度上；

避免分布式系统中多服务器的关联，比如：依赖同一个mysql，程序逻辑中使用分布式锁，导致瓶颈在mysql，分布式又变成串行化运算。

上面说了要避免的地方，要具体怎么来避免，到具体的业务场景就需要具体分析了。

**而且有些时候，为了业务功能，或者其它方面的需求，比如：可用性、伸缩性、扩展性、安全性，不得不牺牲掉一部分性能。**

**最后，做一个总结：**

并发量，是一个容量的概念，服务可以接受的最大任务数量，动态的看待它，还需要把性能考虑进去。

性能，是一个速度的概念，单位时间内可以处理的任务数量。

高并发和高性能是紧密相关的，提高应用的性能，是肯定可以提高系统的并发能力的。

应用性能优化的时候，对于计算密集型和IO密集型还是有很大差别，需要分开来考虑。

增加服务器资源（CPU、内存、服务器数量），绝大部分时候是可以提高应用的并发能力和性能（前提是应用能够支持多任务并行计算，多服务器分布式计算才行），但也是要避免其中的一些问题，才可以更好的更有效率的利用服务器资源。

### MySQL

#### 1. MySQL Innodb/MyIsm

MyISAM是MySQL的默认数据库引擎（5.5版之前），由早期的ISAM（Indexed Sequential Access Method：有索引的顺序访问方法）所改良。虽然性能极佳，但却有一个缺点：不支持事务处理（transaction）。不过，在这几年的发展下，MySQL也导入了InnoDB（另一种数据库引擎），以强化参考完整性与并发违规处理机制，后来就逐渐取代MyISAM。

InnoDB，是MySQL的数据库引擎之一，为MySQL AB发布binary的标准之一。InnoDB由Innobase Oy公司所开发，2006年五月时由甲骨文公司并购。与传统的ISAM与MyISAM相比，InnoDB的最大特色就是支持了ACID兼容的事务（Transaction）功能，类似于PostgreSQL。目前InnoDB采用双轨制授权，一是GPL授权，另一是专有软件授权。

#### 2.MySQL架构

[MySQL架构](https://blog.csdn.net/hguisu/article/details/7106342)

#### 3. MyISAM与InnoDB的区别是什么

##### 1、 存储结构

MyISAM：每个MyISAM在磁盘上存储成三个文件。第一个文件的名字以表的名字开始，扩展名指出文件类型。.frm文件存储表定义。数据文件的扩展名为.MYD (MYData)。索引文件的扩展名是.MYI (MYIndex)。
 InnoDB：所有的表都保存在同一个数据文件中（也可能是多个文件，或者是独立的表空间文件），InnoDB表的大小只受限于操作系统文件的大小，一般为2GB。

##### 2、 存储空间

MyISAM：可被压缩，存储空间较小。支持三种不同的存储格式：静态表(默认，但是注意数据末尾不能有空格，会被去掉)、动态表、压缩表。
 InnoDB：需要更多的内存和存储，它会在主内存中建立其专用的缓冲池用于高速缓冲数据和索引。

##### 3、 可移植性、备份及恢复

MyISAM：数据是以文件的形式存储，所以在跨平台的数据转移中会很方便。在备份和恢复时可单独针对某个表进行操作。
 InnoDB：免费的方案可以是拷贝数据文件、备份 binlog，或者用 mysqldump，在数据量达到几十G的时候就相对痛苦了。

##### 4、 事务支持

MyISAM：强调的是性能，每次查询具有原子性,其执行数度比InnoDB类型更快，但是不提供事务支持。
 InnoDB：提供事务支持事务，外部键等高级数据库功能。 具有事务(commit)、回滚(rollback)和崩溃修复能力(crash recovery capabilities)的事务安全(transaction-safe (ACID compliant))型表。

##### 5、 AUTO_INCREMENT

MyISAM：可以和其他字段一起建立联合索引。引擎的自动增长列必须是索引，如果是组合索引，自动增长可以不是第一列，他可以根据前面几列进行排序后递增。
 InnoDB：InnoDB中必须包含只有该字段的索引。引擎的自动增长列必须是索引，如果是组合索引也必须是组合索引的第一列。

##### 6、 表锁差异

MyISAM：只支持表级锁，用户在操作myisam表时，select，update，delete，insert语句都会给表自动加锁，如果加锁以后的表满足insert并发的情况下，可以在表的尾部插入新的数据。
 InnoDB：支持事务和行级锁，是innodb的最大特色。行锁大幅度提高了多用户并发操作的新能。但是InnoDB的行锁，只是在WHERE的主键是有效的，非主键的WHERE都会锁全表的。

##### 7、 全文索引

MyISAM：支持 FULLTEXT类型的全文索引
 InnoDB：不支持FULLTEXT类型的全文索引，但是innodb可以使用sphinx插件支持全文索引，并且效果更好。

##### 8、 表主键

MyISAM：允许没有任何索引和主键的表存在，索引都是保存行的地址。
 InnoDB：如果没有设定主键或者非空唯一索引，**就会自动生成一个6字节的主键(用户不可见)**，数据是主索引的一部分，附加索引保存的是主索引的值的数据列。

##### 9、 表的具体行数

MyISAM：保存有表的总行数，如果select count(*) from table;会直接取出出该值。 InnoDB：没有保存表的总行数，如果使用select count(*) from table；就会遍历整个表，消耗相当大，但是在加了wehre条件后，myisam和innodb处理的方式都一样。

##### 10、 CURD操作

MyISAM：如果执行大量的SELECT，MyISAM是更好的选择。
 InnoDB：如果你的数据执行大量的INSERT或UPDATE，出于性能方面的考虑，应该使用InnoDB表。DELETE 从性能上InnoDB更优，但DELETE FROM table时，InnoDB不会重新建立表，而是一行一行的删除，在innodb上如果要清空保存有大量数据的表，最好使用truncate table这个命令。

##### 11、 外键

MyISAM：不支持
 InnoDB：支持
 通过上述的分析，基本上可以考虑使用InnoDB来替代MyISAM引擎了，原因是InnoDB自身很多良好的特点，比如事务支持、存储 过程、视图、行级锁定等等，在并发很多的情况下，相信InnoDB的表现肯定要比MyISAM强很多。另外，任何一种表都不是万能的，只用恰当的针对业务类型来选择合适的表类型，才能最大的发挥MySQL的性能优势。如果不是很复杂的Web应用，非关键应用，还是可以继续考虑MyISAM的，这个具体情况可以自己斟酌。

存储引擎选择的基本原则

采用MyISAM引擎

- R/W > 100:1 且update相对较少
- 并发不高
- 表数据量小
- 硬件资源有限

采用InnoDB引擎

- R/W比较小，频繁更新大字段
- 表数据量超过1000万，并发高
- 安全性和可用性要求高

采用Memory引擎

- 有足够的内存
- 对数据一致性要求不高，如在线人数和session等应用
- 需要定期归档数据

#### 4 . MySQL 优化

##### 1. 索引

- 目的

索引的目的在于提高查询效率。

- 原理

通过不断的缩小想要获得数据的范围来筛选出最终想要的结果，同时把随机的事件变成顺序的事件，也就是我们总是通过同一种查找方式来锁定数据。

- 分类
  - index ----普通的索引,数据可以重复
  - fulltext----全文索引，用来对大表的文本域(char，varchar，text)进行索引。语法和普通索引一样
  - unique ----唯一索引,唯一索引,要求所有记录都唯一
  - primary key ----主键索引,也就是在唯一索引的基础上相应的列必须为主键

- 什么情况下需要建立索引
  - 较频繁地作为查询条件的字段
  - 唯一性太差的字段不适合建立索引
  - 更新太频繁地字段不适合创建索引
  - 不会出现在where条件中的字段不该建立索引

- 建索引的几大原则
  - 最左前缀匹配原则，非常重要的原则，mysql会一直向右匹配直到遇到范围查询(>、<、between、like)就停止匹配，比如a = 1 and b = 2 and c > 3 and d = 4 如果建立(a,b,c,d)顺序的索引，d是用不到索引的，如果建立(a,b,d,c)的索引则都可以用到，a,b,d的顺序可以任意调整。
  - =和in可以乱序，比如a = 1 and b = 2 and c = 3 建立(a,b,c)索引可以任意顺序，mysql的查询优化器会帮你优化成索引可以识别的形式
  - 尽量选择区分度高的列作为索引,区分度的公式是count(distinct col)/count(*)，表示字段不重复的比例，比例越大我们扫描的记录数越少，唯一键的区分度是1，而一些状态、性别字段可能在大数据面前区分度就是0，那可能有人会问，这个比例有什么经验值吗？使用场景不同，这个值也很难确定，一般需要join的字段我们都要求是0.1以上，即平均1条扫描10条记录
  - 索引列不能参与计算，保持列“干净”，比如from_unixtime(create_time) = ’2014-05-29’就不能使用到索引，原因很简单，b+树中存的都是数据表中的字段值，但进行检索时，需要把所有元素都应用函数才能比较，显然成本太大。所以语句应该写成create_time = unix_timestamp(’2014-05-29’);
  - 尽量的扩展索引，不要新建索引。比如表中已经有a的索引，现在要加(a,b)的索引，那么只需要修改原来的索引即可
- 工具
  - explain命令
- 慢查询优化的基本步骤
  - 先运行看看是否真的很慢，注意设置SQL_NO_CACHE
  - where条件单表查，锁定最小返回记录表。这句话的意思是把查询语句的where都应用到表中返回的记录数最小的表开始查起，单表每个字段分别查询，看哪个字段的区分度最高
  - explain查看执行计划，是否与1预期一致（从锁定记录较少的表开始查询）
  - order by limit 形式的sql语句让排序的表优先查
  - 了解业务方使用场景
  - 加索引时参照建索引的几大原则
  - 观察结果，不符合预期继续从0分析

2. 隔离级别

   [真正理解Mysql的四种隔离级别](https://www.jianshu.com/p/8d735db9c2c0)

3. 性能瓶颈

   [mysql性能瓶颈分析、性能指标、指标搜集方法与性能分析调优工具](https://www.cnblogs.com/ToDoToTry/p/4392288.html)

4. 性能调优

   [MySQL 性能调优的10个方法](https://www.cnblogs.com/claireyuancy/p/7258314.html)

   [MYSQL性能优化的最佳20+条经验](https://www.cnblogs.com/zhouyusheng/p/8038224.html)

## 3. Redis

### Redis网络模型

[Redis 网络架构及单线程模型](http://blog.jobbole.com/100079/)

###Redis为什么这么快

1、完全基于内存，绝大部分请求是纯粹的内存操作，非常快速。数据存在内存中，类似于HashMap，HashMap的优势就是查找和操作的时间复杂度都是O(1)；

2、数据结构简单，对数据操作也简单，Redis中的数据结构是专门进行设计的；

3、采用单线程，避免了不必要的上下文切换和竞争条件，也不存在多进程或者多线程导致的切换而消耗 CPU，不用去考虑各种锁的问题，不存在加锁释放锁操作，没有因为可能出现死锁而导致的性能消耗；

4、使用多路I/O复用模型，非阻塞IO；

5、使用底层模型不同，它们之间底层实现方式以及与客户端之间通信的应用协议不一样，Redis直接自己构建了VM 机制 ，因为一般的系统调用系统函数的话，会浪费一定的时间去移动和请求；

以上几点都比较好理解，下边我们针对多路 I/O 复用模型进行简单的探讨：

（1）多路 I/O 复用模型

多路I/O复用模型是利用 select、poll、epoll 可以同时监察多个流的 I/O 事件的能力，在空闲的时候，会把当前线程阻塞掉，当有一个或多个流有 I/O 事件时，就从阻塞态中唤醒，于是程序就会轮询一遍所有的流（epoll 是只轮询那些真正发出了事件的流），并且只依次顺序的处理就绪的流，这种做法就避免了大量的无用操作。

这里“多路”指的是多个网络连接，“复用”指的是复用同一个线程。采用多路 I/O 复用技术可以让单个线程高效的处理多个连接请求（尽量减少网络 IO 的时间消耗），且 Redis 在内存中操作数据的速度非常快，也就是说内存内的操作不会成为影响Redis性能的瓶颈，主要由以上几点造就了 Redis 具有很高的吞吐量。

### 那么为什么Redis是单线程的

我们首先要明白，上边的种种分析，都是为了营造一个Redis很快的氛围！官方FAQ表示，因为Redis是基于内存的操作，CPU不是Redis的瓶颈，Redis的瓶颈最有可能是机器内存的大小或者网络带宽。既然单线程容易实现，而且CPU不会成为瓶颈，那就顺理成章地采用单线程的方案了（毕竟采用多线程会有很多麻烦！）。

![这里写图片描述](https://img-blog.csdn.net/20180307162652293?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMDg3MDUxOA==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70) 
可以参考：<https://redis.io/topics/faq>

看到这里，你可能会气哭！本以为会有什么重大的技术要点才使得Redis使用单线程就可以这么快，没想到就是一句官方看似糊弄我们的回答！但是，我们已经可以很清楚的解释了为什么Redis这么快，并且正是由于在单线程模式的情况下已经很快了，就没有必要在使用多线程了！

但是，我们使用单线程的方式是无法发挥多核CPU 性能，不过我们可以通过在单机开多个Redis 实例来完善！

警告1：这里我们一直在强调的单线程，只是在处理我们的网络请求的时候只有一个线程来处理，一个正式的Redis Server运行的时候肯定是不止一个线程的，这里需要大家明确的注意一下！例如Redis进行持久化的时候会以子进程或者子线程的方式执行（具体是子线程还是子进程待读者深入研究）；例如我在测试服务器上查看Redis进程，然后找到该进程下的线程：

![这里写图片描述](https://img-blog.csdn.net/20180307172053108?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMDg3MDUxOA==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

ps命令的“-T”参数表示显示线程（Show threads, possibly with SPID column.）“SID”栏表示线程ID，而“CMD”栏则显示了线程名称。

警告2：在上图中FAQ中的最后一段，表述了从Redis 4.0版本开始会支持多线程的方式，但是，只是在某一些操作上进行多线程的操作！所以该篇文章在以后的版本中是否还是单线程的方式需要读者考证！

## 注意点

1、我们知道Redis是用”单线程-多路复用IO模型”来实现高性能的内存数据服务的，这种机制避免了使用锁，但是同时这种机制在进行sunion之类的比较耗时的命令时会使redis的并发下降。因为是单一线程，所以同一时刻只有一个操作在进行，所以，耗时的命令会导致并发的下降，不只是读并发，写并发也会下降。而单一线程也只能用到一个CPU核心，所以可以在同一个多核的服务器中，可以启动多个实例，组成master-master或者master-slave的形式，耗时的读命令可以完全在slave进行。

需要改的redis.conf项：

```
pidfile /var/run/redis/redis_6377.pid  #pidfile要加上端口号
port 6377  #这个是必须改的
logfile /var/log/redis/redis_6377.log #logfile的名称也加上端口号
dbfilename dump_6377.rdb  #rdbfile也加上端口号
```

2、“我们不能任由操作系统负载均衡，因为我们自己更了解自己的程序，所以，我们可以手动地为其分配CPU核，而不会过多地占用CPU，或是让我们关键进程和一堆别的进程挤在一起。”。 
CPU 是一个重要的影响因素，由于是单线程模型，Redis 更喜欢大缓存快速 CPU， 而不是多核

在多核 CPU 服务器上面，Redis 的性能还依赖NUMA 配置和处理器绑定位置。最明显的影响是 redis-benchmark 会随机使用CPU内核。为了获得精准的结果，需要使用固定处理器工具（在 Linux 上可以使用 taskset）。最有效的办法是将客户端和服务端分离到两个不同的 CPU 来高校使用三级缓存。

### 单进程单线程的Redis如何能够高并发

[单进程单线程的Redis如何能够高并发](https://blog.csdn.net/liupeng_qwert/article/details/77263187)

### 扩展

以下也是你应该知道的几种模型，祝你的面试一臂之力！

1、单进程多线程模型：MySQL、Memcached、Oracle（Windows版本）；

2、多进程模型：Oracle（Linux版本）；

3、Nginx有两类进程，一类称为Master进程(相当于管理进程)，另一类称为Worker进程（实际工作进程）。启动方式有两种：

（1）单进程启动：此时系统中仅有一个进程，该进程既充当Master进程的角色，也充当Worker进程的角色。

（2）多进程启动：此时系统有且仅有一个Master进程，至少有一个Worker进程工作。

（3）Master进程主要进行一些全局性的初始化工作和管理Worker的工作；事件处理是在Worker中进行的。

![这里写图片描述](https://img-blog.csdn.net/20180307172918264?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMDg3MDUxOA==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

### 当数据大于Redis内存时，Redis做了什么操作

 [Redis性能问题排查解决手册(七)](https://www.cnblogs.com/mushroom/p/4738170.html)

## 6. 分布式原理

分布式系统是由一组通过网络进行通信、为了完成共同的任务而协调工作的计算机节点组成的系统。分布式系统的出现是为了用廉价的、普通的机器完成单个计算机无法完成的计算、存储任务。其目的是**利用更多的机器，处理更多的数据**。

那么分布式系统怎么将任务分发到这些计算机节点呢，很简单的思想，分而治之，即分片（**partition）**。对于计算，那么就是对计算任务进行切换，每个节点算一些，最终汇总就行了，这就是MapReduce的思想；对于存储，更好理解一下，每个节点存一部分数据就行了。当数据规模变大的时候，Partition是唯一的选择，同时也会带来一些好处：

　　（1）提升性能和并发，操作被分发到不同的分片，相互独立

　　（2）提升系统的可用性，即使部分分片不能用，其他分片不会受到影响

Partition和Replication是解决分布式系统问题的一记组合拳，很多具体的问题都可以用这个思路去解决。但这并不是银弹，往往是为了解决一个问题，会引入更多的问题，比如为了可用性与可靠性保证，引用了冗余（复制集）。有了冗余，各个副本间的一致性问题就变得很头疼，一致性在系统的角度和用户的角度又有不同的等级划分。如果要保证强一致性，那么会影响可用性与性能，在一些应用（比如电商、搜索）是难以接受的。如果是最终一致性，那么就需要处理数据冲突的情况。CAP、FLP这些理论告诉我们，在分布式系统中，没有最佳的选择，都是需要权衡，做出最合适的选择。

### 分布式系统挑战

分布式系统需要大量机器协作，面临诸多的挑战：

　　第一，异构的机器与网络：

　　　　分布式系统中的机器，配置不一样，其上运行的服务也可能由不同的语言、架构实现，因此处理能力也不一样；节点间通过网络连接，而不同网络运营商提供的网络的带宽、延时、丢包率又不一样。怎么保证大家齐头并进，共同完成目标，这四个不小的挑战。

　　第二，普遍的节点故障：

　　　　虽然单个节点的故障概率较低，但节点数目达到一定规模，出故障的概率就变高了。分布式系统需要保证故障发生的时候，系统仍然是可用的，这就需要监控节点的状态，在节点故障的情况下将该节点负责的计算、存储任务转移到其他节点

　　第三，不可靠的网络：

　　　　节点间通过网络通信，而网络是不可靠的。可能的网络问题包括：网络分割、延时、丢包、乱序。

　　　　相比单机过程调用，网络通信最让人头疼的是超时：节点A向节点B发出请求，在约定的时间内没有收到节点B的响应，那么B是否处理了请求，这个是不确定的，这个不确定会带来诸多问题，最简单的，是否要重试请求，节点B会不会多次处理同一个请求。 

### 分布式系统特性与衡量标准

　　透明性：使用分布式系统的用户并不关心系统是怎么实现的，也不关心读到的数据来自哪个节点，对用户而言，分布式系统的最高境界是用户根本感知不到这是一个分布式系统，在《[Distributed Systems Principles and Paradigms](http://barbie.uta.edu/~jli/Resources/MapReduce&Hadoop/Distributed%20Systems%20Principles%20and%20Paradigms.pdf)》一书中，作者是这么说的：

> A distributed system is a collection of independent computers that appears to its users as a single coherent system.　　

　　可扩展性：分布式系统的根本目标就是为了处理单个计算机无法处理的任务，当任务增加的时候，分布式系统的处理能力需要随之增加。简单来说，要比较方便的通过增加机器来应对数据量的增长，同时，当任务规模缩减的时候，可以撤掉一些多余的机器，达到动态伸缩的效果

　　可用性与可靠性：一般来说，分布式系统是需要长时间甚至7*24小时提供服务的。可用性是指系统在各种情况对外提供服务的能力，简单来说，可以通过不可用时间与正常服务时间的必知来衡量；而可靠性而是指计算结果正确、存储的数据不丢失。

　　高性能：不管是单机还是分布式系统，大家都非常关注性能。不同的系统对性能的衡量指标是不同的，最常见的：高并发，单位时间内处理的任务越多越好；低延迟：每个任务的平均时间越少越好。这个其实跟操作系统CPU的调度策略很像

　　一致性：分布式系统为了提高可用性可靠性，一般会引入冗余（复制集）。那么如何保证这些节点上的状态一致，这就是分布式系统不得不面对的一致性问题。一致性有很多等级，一致性越强，对用户越友好，但会制约系统的可用性；一致性等级越低，用户就需要兼容数据不一致的情况，但系统的可用性、并发性很高很多。

## 7. Python底层怎么实现一个字典对象

## 8. 海量数据处理

### TOP N问题

1. 如何在海量数据中找出重复最多一个。

- 通过hash映射为小文件
- 通过hash_map统计各个小文件重读最多的并记录次数
- 对每个小文件重复最多的进行建立大根堆

2. 上亿有重数据，统计最多前N个。

- 内存存不下
  - 通过hash映射为小文件
  - 通过hash_map统计各个小文件重读最多的并记录次数
  - 对每个小文件重复最多的进行建立大根堆并重复N次取走堆顶并重建堆操作
- 内存存得下
  - 直接内存通过hash_map统计并建大根堆
  - 重复N次取走堆顶并重建堆操作

3. 海量日志数据，提取出某日访问百度次数最多的那个IP（同1）。

- 将IP % 1000映射到1000个小文件中
  - 相同IP会被映射到同一个文件
  - 不会出现累加和更大情况
- 分1000次在内存处理小文件，得到频率最大IP（使用map统计）
- 对这1000个IP建立大根堆

4. 1000w查询串统计最热门10个（同2）。

同上

5. 1G的文件，里面1行1个不超过16字节的词。内存限制1M，返回频数最高前100（同2）。

- 将单词 % 5000存入5000小文件
- 平均各文件约200K
- 对超过1M的文件继续分割直到小于200K
- 使用map统计各个词出现的频率
- 对5000词使用堆排序或归并排序

### 分布式TOP N问题

1. 分布在100台电脑的海量数据，统计前十

- 各数据只出现在一台机器中
  - 先在独立机器得到前十
    - 若可以放入内存直接堆排序
    - 若不可全放入内存：哈希分块 -> map统计 -> 归总堆排
  - 再将100台计算机的TOP10组合起来堆排序
- 同一元素可同时出现在不同机器中
  - 遍历所有数据，重新hash取模，使同一个元素只出现在单独的一台电脑中，然后采用上面方法先统计每台电脑TOP10再汇总起来

## 9. select/epoll/poll IO多路复用

[select、poll和epoll的区别](https://github.com/xiezg247/Capricorn/blob/master/docs/笔记/知识体系/操作系统/select、poll、和epoll的区别.md)

## 10. Python内存管理

### Python内存管理机制

Python有两种共存的内存管理机制: *引用计数*和*垃圾回收*. 引用计数是一种非常高效的内存管理手段, 当一个Python对象被引 用时其引用计数增加1, 当其不再被一个变量引用时则计数减1. 当引用计数等于0时对象被删除.

## 垃圾回收机制

本节将简单介绍Python的垃圾回收机制. [Garbage Collection for Python](http://arctrix.com/nas/python/gc/) 以及Python垃圾回收[源码](http://svn.python.org/view/python/trunk/Modules/gcmodule.c?revision=81029&view=markup) 中的注释进行了更详细的解释.

在Python中, 所有能够引用其他对象的对象都被称为容器(container). 因此只有容器之间才可能形成循环引用. Python的垃圾回收机制利用了这个特点来寻找需要被释放的对象. 为了记录下所有的容器对象, Python将每一个 容器都链到了一个双向链表中, 之所以使用双向链表是为了方便快速的在容器集合中插入和删除对象. 有了这个 维护了所有容器对象的双向链表以后, Python在垃圾回收时使用如下步骤来寻找需要释放的对象:

1. 对于每一个容器对象, 设置一个`gc_refs`值, 并将其初始化为该对象的引用计数值.
2. 对于每一个容器对象, 找到所有其引用的对象, 将被引用对象的`gc_refs`值减1.
3. 执行完步骤2以后所有`gc_refs`值还大于0的对象都被非容器对象引用着, 至少存在一个非循环引用. 因此 不能释放这些对象, 将他们放入另一个集合.
4. 在步骤3中不能被释放的对象, 如果他们引用着某个对象, 被引用的对象也是不能被释放的, 因此将这些 对象也放入另一个集合中.
5. 此时还剩下的对象都是无法到达的对象. 现在可以释放这些对象了.

值得注意的是, 如果一个Python对象含有`__del__`这个方法, Python的垃圾回收机制即使发现该对象不可到达 也不会释放他. 原因是`__del__`这个方式是当一个Python对象引用计数为0即将被删除前调用用来做清理工作的. 由于垃圾回收找到的需要释放的对象中往往存在循环引用的情况, 对于循环引用的对象`a`和`b`, 应该先调用哪 一个对象的`__del__`是无法决定的, 因此Python垃圾回收机制就放弃释放这些对象, 转而将这些对象保存起来, 通过`gc.garbage`这个变量访问. 程序员可以通过`gc.garbage`手动释放对象, 但是更好的方法是避免在代码中 定义`__del__`这个方法.

除此之外, Python还将所有对象根据’生存时间’分为3代, 从0到2. 所有新创建的对象都分配为第0代. 当这些对象 经过一次垃圾回收仍然存在则会被放入第1代中. 如果第1代中的对象在一次垃圾回收之后仍然存货则被放入第2代. 对于不同代的对象Python的回收的频率也不一样. 可以通过`gc.set_threshold(threshold0[, threshold1[, threshold2]])` 来定义. 当Python的垃圾回收器中新增的对象数量减去删除的对象数量大于threshold0时, Python会对第0代对象 执行一次垃圾回收. 每当第0代被检查的次数超过了threshold1时, 第1代对象就会被执行一次垃圾回收. 同理每当 第1代被检查的次数超过了threshold2时, 第2代对象也会被执行一次垃圾回收.

由于Python的垃圾回收需要检查所有的容器对象, 因此当一个Python程序生产了大量的对象时, 执行一次垃圾回收将 带来可观的开销. 因此可以通过一些手段来尽量避免垃圾回收以提高程序的效率.

## 调优手段

### 手动垃圾回收

对Python的垃圾回收进行调优的一个最简单的手段便是关闭自动回收, 根据情况手动触发. 例如在用Python开发游戏时, 可以在一局游戏的开始关闭GC, 然后在该局游戏结束后手动调用一次GC清理内存. 这样能完全避免在游戏过程中因此 GC造成卡顿. 但是缺点是在游戏过程中可能因为内存溢出导致游戏崩溃.

### 调高垃圾回收阈值

相比完全手动的垃圾回收, 一个更温和的方法是调高垃圾回收的阈值. 例如一个游戏可能在某个时刻产生大量的子弹对象(假如是2000个). 而此时Python的垃圾回收的threshold0为1000. 则一次垃圾回收会被触发, 但这2000个子弹对象并不需要被回收. 如果此时 Python的垃圾回收的threshold0为10000, 则不会触发垃圾回收. 若干秒后, 这些子弹命中目标被删除, 内存被引用计数机制 自动释放, 一次(可能很耗时的)垃圾回收被完全的避免了.

调高阈值的方法能在一定程度上避免内存溢出的问题(但不能完全避免), 同时可能减少可观的垃圾回收开销. 根据具体项目 的不同, 甚至是程序输入的不同, 合适的阈值也不同. 因此需要反复测试找到一个合适的阈值, 这也算调高阈值这种手段 的一个缺点.

### 避免循环引用

一个可能更好的方法是使用良好的编程习惯尽可能的避免循环引用. 两种常见的手段包括: 手动解循环引用和使用弱引用.

#### 手动解循环引用

手动解循环引用指在编写代码时写好解开循环引用的代码, 在一个对象使用结束不再需要时调用.

#### 使用弱引用

弱引用指当引用一个对象时, 不增加该对象的引用计数, 当需要使用到该对象的时候需要首先检查该对象是否还存在. 弱引用的实现方式有多种, Python自带一个弱引用库`weakref`, 其详细文档参加[这里](https://docs.python.org/2/library/weakref.html). 

## 11. 性能优化

[[python性能优化](https://www.cnblogs.com/xybaby/p/6510941.html)](https://www.cnblogs.com/xybaby/p/6510941.html)

## 12. Python 进程间通信

### 进程通信的目的

------

- **数据传输** 
  一个进程需要将它的数据发送给另一个进程，发送的数据量在一个字节到几M字节之间
- **共享数据** 
  多个进程想要操作共享数据，一个进程对共享数据
- **通知事** 
  一个进程需要向另一个或一组进程发送消息，通知它（它们）发生了某种事件（如进程终止时要通知父进程）。
- **资源共享** 
  多个进程之间共享同样的资源。为了作到这一点，需要内核提供锁和同步机制。
- **进程控制** 
  有些进程希望完全控制另一个进程的执行（如Debug进程），此时控制进程希望能够拦截另一个进程的所有陷入和异常，并能够及时知道它的状态改变。

### linux使用的进程间通信方式

------

1. 管道（pipe）,流管道(s_pipe)和有名管道（FIFO）
2. 信号（signal）
3. 消息队列( message queue )
4. 共享内存( shared memory )
5. 信号量( semophore ） 
6. 套接字（socket)

### 各种通信方式的比较和优缺点

1. 管道：速度慢，容量有限，只有父子进程能通讯
2. FIFO：任何进程间都能通讯，但速度慢
3. 消息队列：容量受到系统限制，且要注意第一次读的时候，要考虑上一次没有读完数据的问题
4. 信号量：不能传递复杂消息，只能用来同步
5. 共享内存区：能够很容易控制容量，速度快，但要保持同步，比如一个进程在写的时候，另一个进程要注意读写的问题，相当于线程中的线程安全，当然，共享内存区同样可以用作线程间通讯，不过没这个必要，线程间本来就已经共享了同一进程内的一块内存

### python 多进程 —— 进程间通信

## **multiprocessing.Queue()**

以Queue为例，在父进程中创建两个子进程，一个往`Queue`里写数据，一个从`Queue`里读数据：

`multiprcessing.Queue.put()` 为 入队操作

`multiprcessing.Queue.get()` 为 出队操作

## **multiprocessing.Pipe()**

Pipe（）函数返回一对由管道连接的连接对象，默认情况下是双工（双向）。

Pipe（）返回的两个连接对象代表管道的两端。 每个连接对象都有send（）和recv（）方法（等等）。 请注意，如果两个进程（或线程）尝试同时读取或写入管道的同一端，管道中的数据可能会损坏。 当然，同时使用管道不同端的过程也不会有风险。

## 13. Python 语言架构

[Python源码剖析学习笔记](https://github.com/xiezg247/Capricorn/blob/master/docs/笔记/专业技能/编程语言/Python/Python源码剖析学习笔记.md)

## 14. 数据结构 链表/树/哈希表

## 15. 算法 随机/排序/贪心

## 16. 设计模式 单例模式实现

## 17. Python语言特性

## 18. Nginx

## 19. 任务队列 

